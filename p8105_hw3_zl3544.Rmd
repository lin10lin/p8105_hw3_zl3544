---
title: "p8105_hw3_zl3544"
output: html_document
date: "2024-10-14"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(lubridate)
library(ggplot2)
library(ggridges)
library(tidyverse)
library(p8105.datasets)
library(patchwork)
library(hexbin) 
```

# Problem 1

## Exploration of the dataset
```{r}
# Display the structure of the dataset
str(ny_noaa)

# Get the number of rows and columns
nrow(ny_noaa)
ncol(ny_noaa)

# Display the dimensions of the dataset
dim(ny_noaa)

# Show the structure again for a detailed overview
str(ny_noaa)

# Provide a summary of the dataset
summary(ny_noaa)
```
### Description of the dataset

The dataset have 2595176 and 7 columns, which means that the ny_noaa dataset has 2,595,176 observations and 7 variables. The variables includes: id(Weather station identifier),date(Date of the observation), prcp(Precipitation (tenths of mm)), snow(Snowfall (mm)), snwd(Snow depth (mm)),tmax(Maximum temperature (tenths of degrees C)), tmin(Minimum temperature (tenths of degrees C)). In the summary, we can see that: prcp has a mean 29.82, the min is 0 and the max is 22860; snow has a mean 5, the min is -13 and the max is 10160; snwd has a mean 37.3, the min is 0 and the max is 9195. Also， there are missing value in some variables.

### Missing data

Caculate the percentage of missing data:
```{r}
ny_noaa %>%
  summarise(
    missing_prcp = mean(is.na(prcp)) * 100,
    missing_snow = mean(is.na(snow)) * 100,
    missing_snwd = mean(is.na(snwd)) * 100,
    missing_tmax = mean(is.na(tmax)) * 100,
    missing_tmin = mean(is.na(tmin)) * 100
  )

```
5.62% of prcp values are missing, 14.68% of snow values are missing,22.80% of snwd values are missing, 43.69% tmax are missing, 46.23% of tmin are missing.

## Data cleaning
```{r}
ny_noaa_cleaned= ny_noaa %>%
  janitor::clean_names() %>% 
  mutate(
    year = year(date),
    month = month(date),
    day = day(date),
    prcp = as.numeric(prcp)/10,
    tmax = as.numeric(tmax)/10,
    tmin = as.numeric(tmin)/10
  ) %>% 
  filter(tmax > tmin | is.na(tmax) | is.na(tmin)) %>% 
  filter(!(is.na(snow) & is.na(snwd) & is.na(tmax) & is.na(tmin) & is.na(prcp)))
head(ny_noaa_cleaned)
```
The data cleaning process: 

* Create separate variables for year, month, and day. 

* Ensure observations for temperature, precipitation, and snowfall are given in reasonable units.

* Ensures that only keep observations where the temperature data makes sense (i.e., maximum temperatures are logically higher than minimum temperatures)

* Filtered out rows in a dataset where all of the specified variables (snow, snwd, tmax, tmin, and prcp) are missing.

### Most common snowfall values:
```{r}
ny_noaa_cleaned %>% 
  count(snow) %>% 
  arrange(desc(n)) 
```
According to the table, 0 is the most common snowfall value.

## Making plots:
### A two-panel plot showing the average max temperature in January and in July in each station across years
```{r}
mean_temps <- ny_noaa_cleaned %>%
  filter(month %in% c(1, 7)) %>%
  group_by(id, year, month) %>%
  summarise(mean_tmax = mean(tmax, na.rm = TRUE), .groups = 'drop') %>%
  mutate(month = if_else(month == 1, "January", "July"))
```
```{r}
avg_tmax_plot <- ggplot(mean_temps, aes(x = year, y = mean_tmax, color = month)) +
  geom_point() +            # Add points
  geom_line() +             # Connect points with lines
  facet_grid(.~ month, labeller = labeller(month = c(`1` = "January", `7` = "July"))) +
  labs(title = "Average Max Temperature in January and July by Station",
       x = "Year",
       y = "Average Max Temperature (°C)",
       color = "Month") +
  theme_minimal() +        # Use a minimal theme
  theme(legend.position = "bottom")  # Position the legend

# Display the plot
print(avg_tmax_plot)
```

The plot indicates that there are significant differences  between the average max temperature in January and in July. The plot shows mean maximum temperatures in January below 0°C for many stations, mean maximum temperatures in July generally around 25°C to 30°C. There are some outliers in January, for example, the year 2005, it indicates that the year 2005 is extremely cold in the winter, there are also some outliers in July. But the temperature in July is always higher than January.
## Combined plot
```{r}
# Hexbin plot for tmax vs tmin
hexbin_plot = ggplot(ny_noaa_cleaned, aes(x = tmin, y = tmax)) + 
  geom_hex() + 
  labs(title = "Relationship Between Minimum and Maximum Temperatures",
       x = "t_min (°C)",
       y = "t_max (°C)")+
  theme_minimal()
```
```{r}
# Plot showing the distribution of snowfall values
violin_plot = ny_noaa_cleaned %>% 
  filter(snow > 0 & snow< 100) %>% 
  ggplot(aes(x = as.factor(year), y =snow, color = as.character(year))) + 
  geom_violin()+
  labs(
    x = "Year",
    y = "Snowfall (mm)",
    title = "Distribution of Snowfall Values Greater Than 0 and Less Than 100 by Year"
  ) +
theme(legend.position='none',
        axis.text.x = element_text(angle = 60,vjust = 0.88,hjust = 0.77))
hexbin_plot + violin_plot + plot_layout(heights = c(3,2))
```

# Problem 2
## Read data
```{r}
demo= read_csv('./data/nhanes_covar.csv',na = c("NA", ".", ""), skip = 4) %>% 
  janitor::clean_names()
accelerometer=read_csv('./data/nhanes_accel.csv', na = c("NA", ".", "")) %>% 
  janitor::clean_names()
```
Notice that the accelerometer dataset is not tidy, "min1","min2",...

## Data cleaning

Merge, tidy and clean the data, exclude participants less than 21 years of age, and those with missing demographic data, and encode data with reasonable variable classes:
```{r}
demo=demo %>% 
  filter(age>=21) %>% 
  drop_na
anti_join(demo, accelerometer, by = "seqn")
merged_df= left_join(demo, accelerometer, by = "seqn") %>% 
  pivot_longer(
    min1:min1440,
    names_to = "minute",
    values_to = "MIMS"
  ) %>% 
  mutate(
    sex = factor(sex, levels = c(1, 2), labels = c('male','female')),
    education = factor(education, levels = c(1, 2, 3), labels = c('Less than high school','High school equivalent','More than high school')),
    ) 
head(merged_df)
```
## Produce a reader-friendly table for the number of men and women in each education category
```{r}
count_sex_education=merged_df %>% 
  select(seqn,sex,education) %>% 
  #ensuring that only unique entries are retained
  unique() %>% 
  # will be used to count participants
  mutate(num = 1) %>% 
  # The data is grouped by sex and education, and the total count (number) is calculated for each group
  group_by(sex, education) %>% 
  summarise(number = sum(num), .groups = 'keep')
reader_table= count_sex_education %>% 
  pivot_wider(
    names_from = 'education',
    values_from = 'number'
  )
reader_table
```
Then transformed the table to graph to get a clearer view:
```{r}
plot_count_sex_education=merged_df %>% 
  select(seqn,sex,education) %>% 
  #ensuring that only unique entries are retained
  unique() %>% 
  # will be used to count participants
  mutate(num = 1) %>% 
  # The data is grouped by sex and education, and the total count (number) is calculated for each group
  group_by(sex, education) %>% 
  summarise(number = sum(num), .groups = 'keep') %>% 
  ggplot(aes(x = education, y = number))+
  theme_minimal()+
  labs(title=" The number of men and women in each education category")+
  theme(axis.text.x = element_text(angle = 33,vjust = 0.88,hjust = 0.77))+
  geom_col(aes(fill=sex), position = position_dodge2(preserve = 'single')) +
  geom_text(aes(label=number), 
            position = position_dodge2(width = 1, preserve = 'single'), 
            vjust = -0.3, hjust = 0.6)
plot_count_sex_education
```
Create a visualization of the age distributions for men and women in each education category:
```{r}
distribution_sex=merged_df %>% 
  select(seqn, sex, education) %>% 
  unique() %>% 
  ggplot(aes(x = education)) +
  geom_bar(aes(fill = sex), position = 'fill')+
  labs(title="The age distributions for men and women in each education category")+
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 33,vjust = 0.88,hjust = 0.77))
distribution_sex
```